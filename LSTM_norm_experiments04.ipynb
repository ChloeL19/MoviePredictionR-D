{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloeloughridge/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# normalized VGG16 feature data fed into simple LSTM\n",
    "\n",
    "# First, import necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting up the keras stuff\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import LSTM\n",
    "# my custom data_utils file\n",
    "from data_utils_local08 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 212, 4096)\n"
     ]
    }
   ],
   "source": [
    "# uploading the X values\n",
    "#X_input = np.load('../Desktop/Cloud_Training/data/VGG16_data01.npy')[7:, :212, :] #VGG16 data\n",
    "\n",
    "X_input = np.load('../Desktop/VGG16_feature_data.npy')\n",
    "\n",
    "#X_input = np.load('VGG16.npy')\n",
    "# X_input = np.load('../Desktop/InceptionResNetV2_feature_data.npy') #resnet data!\n",
    "\n",
    "\n",
    "\n",
    "#X_input = np.load('../Desktop/audio_feature_data.npy') #audio feature data!\n",
    "\n",
    "print(X_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yey\n"
     ]
    }
   ],
   "source": [
    "X_input2 = np.load('../Desktop/Cloud_Training/data/VGG16_data01.npy')[7:, :212, :]\n",
    "if X_input2.all() == X_input.all():\n",
    "    print('yey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2035225048923679\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n"
     ]
    }
   ],
   "source": [
    "# uploading the Y values\n",
    "#y_data_input = np.load('../Desktop/Cloud_Training/data/labels01.npy')[7:, :212]\n",
    "y_data_input = np.load('../Desktop/labels.npy')\n",
    "#y_data_input = np.load('labels.npy')\n",
    "balance = np.mean(y_data_input)\n",
    "print(balance)\n",
    "print(y_data_input)\n",
    "for mov in y_data_input:\n",
    "    if mov.any()==1:\n",
    "        print('yey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 212, 4096) (4, 212, 4096) (4, 212) (3, 212)\n"
     ]
    }
   ],
   "source": [
    "timesteps = X_input.shape[1]\n",
    "data_dim = X_input.shape[2]\n",
    "\n",
    "X_train = X_input[:4,:timesteps, :]\n",
    "Y_train = y_data_input[:4, :timesteps]\n",
    "\n",
    "X_test = X_input[4:, :timesteps, :]\n",
    "Y_test = y_data_input[4:, :timesteps]\n",
    "\n",
    "print(X_test.shape, X_train.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constructing a many-to-one LSTM model in keras \n",
    "model = Sequential()\n",
    "\n",
    "# normalization\n",
    "model.add(BatchNormalization(input_shape=(timesteps, data_dim)))\n",
    "\n",
    "model.add(LSTM(timesteps, return_sequences=True))\n",
    "#input_shape=(timesteps, data_dim)\n",
    "\n",
    "model.add(Flatten()) \n",
    "# add the final dense layer and then softmax\n",
    "model.add(Dense(timesteps, activation='sigmoid'))\n",
    "# going to add a softmax activation to this\n",
    "#model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a new metric of evaluation! the F-score!\n",
    "def FScore2(y_true, y_pred):\n",
    "    '''\n",
    "    The F score, beta=2\n",
    "    '''\n",
    "    B2 = K.variable(4)\n",
    "    OnePlusB2 = K.variable(5)\n",
    "    pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(K.less(K.abs(pred - K.clip(y_true, .5, 1.)), 0.01), 'float32'), -1)\n",
    "    fp = K.sum(K.cast(K.greater(pred - y_true, 0.1), 'float32'), -1)\n",
    "    fn = K.sum(K.cast(K.less(pred - y_true, -0.1), 'float32'), -1)\n",
    "\n",
    "    f2 = OnePlusB2 * tp / (OnePlusB2 * tp + B2 * fn + fp)\n",
    "\n",
    "    return K.mean(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compiling LSTM model\n",
    "# note that Ng used an Adam optimizer and categorical cross-entropy loss\n",
    "# but this is a binary classification problem so I think the parameters below should suffice\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['binary_accuracy', FScore2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples, validate on 3 samples\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 5s 1s/step - loss: 7.8222e-06 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.4668 - val_binary_accuracy: 0.6808 - val_FScore2: 0.1595\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 4s 876ms/step - loss: 6.2094e-06 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.4748 - val_binary_accuracy: 0.6792 - val_FScore2: 0.1814\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 3s 869ms/step - loss: 4.7627e-06 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.4837 - val_binary_accuracy: 0.6777 - val_FScore2: 0.1811\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 3s 862ms/step - loss: 3.6398e-06 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.4930 - val_binary_accuracy: 0.6730 - val_FScore2: 0.1802\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 4s 883ms/step - loss: 2.8124e-06 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.5021 - val_binary_accuracy: 0.6667 - val_FScore2: 0.1791\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 4s 1s/step - loss: 2.2198e-06 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.5111 - val_binary_accuracy: 0.6635 - val_FScore2: 0.1786\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 4s 991ms/step - loss: 1.7894e-06 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.5202 - val_binary_accuracy: 0.6588 - val_FScore2: 0.1778\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.4705e-06 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.5292 - val_binary_accuracy: 0.6588 - val_FScore2: 0.1864\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.2275e-06 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.5379 - val_binary_accuracy: 0.6557 - val_FScore2: 0.1859\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 4s 999ms/step - loss: 1.0420e-06 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.5462 - val_binary_accuracy: 0.6557 - val_FScore2: 0.1888\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 4s 1s/step - loss: 8.9465e-07 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.5540 - val_binary_accuracy: 0.6572 - val_FScore2: 0.1976\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 4s 980ms/step - loss: 7.7752e-07 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.5614 - val_binary_accuracy: 0.6572 - val_FScore2: 0.1976\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 4s 988ms/step - loss: 6.8482e-07 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.5684 - val_binary_accuracy: 0.6541 - val_FScore2: 0.1969\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 4s 956ms/step - loss: 6.0865e-07 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.5748 - val_binary_accuracy: 0.6541 - val_FScore2: 0.1969\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 4s 996ms/step - loss: 5.4516e-07 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.5806 - val_binary_accuracy: 0.6525 - val_FScore2: 0.1966\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 5s 1s/step - loss: 4.9347e-07 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.5861 - val_binary_accuracy: 0.6525 - val_FScore2: 0.1966\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 5s 1s/step - loss: 4.5005e-07 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.5913 - val_binary_accuracy: 0.6509 - val_FScore2: 0.1962\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 4s 1000ms/step - loss: 4.1479e-07 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.5962 - val_binary_accuracy: 0.6525 - val_FScore2: 0.1994\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.8332e-07 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.6007 - val_binary_accuracy: 0.6541 - val_FScore2: 0.1998\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 4s 1s/step - loss: 3.5680e-07 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.6049 - val_binary_accuracy: 0.6541 - val_FScore2: 0.1998\n",
      "finished training!\n"
     ]
    }
   ],
   "source": [
    "# running the LSTM model\n",
    "model.fit(X_train, Y_train, epochs = 20, batch_size = 128, validation_data=(X_test, Y_test))\n",
    "print(\"finished training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "3/3 [==============================] - 2s 523ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.604862093925476, 0.654088020324707, 0.19976860284805298]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save('./VGG16_norm_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model prediction:\n",
      "[1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.9221041e-28 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 2.1595651e-19\n",
      " 1.0000000e+00 1.0000000e+00 2.3602658e-26 1.0000000e+00 1.0000000e+00\n",
      " 4.4973351e-18 3.1209957e-32 1.9935814e-32 3.3743915e-34 1.0000000e+00\n",
      " 1.0000000e+00 2.1284409e-12 1.6664713e-14 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.7663178e-08 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 2.7702462e-30 2.5049629e-30 1.0000000e+00\n",
      " 2.6652263e-31 4.6479136e-31 2.5350656e-34 4.2515438e-35 4.0209436e-32\n",
      " 1.0000000e+00 9.4842254e-15 1.0000000e+00 1.4375714e-11 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.8088938e-24\n",
      " 1.0000000e+00 6.0328166e-31 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 5.4377756e-24 2.0324037e-26 2.3054504e-33 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 3.2671697e-33 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 3.5934445e-20 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 2.7788974e-27 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 9.1861849e-23 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 2.3497778e-22 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.2417668e-27 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 4.2949742e-33\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0679519e-22 1.0000000e+00]\n",
      "target:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "before 64:\n",
      "1.4375714e-11\n",
      "64:\n",
      "1.0\n",
      "rounded\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# trying to view the model output\n",
    "out = model.predict(X_train)\n",
    "\n",
    "movie_index = 1\n",
    "\n",
    "print(\"model prediction:\")\n",
    "print(out[movie_index])\n",
    "print(\"target:\")\n",
    "print(Y_train[movie_index])\n",
    "\n",
    "print(\"before 64:\")\n",
    "print(out[movie_index][63])\n",
    "print(\"64:\")\n",
    "print(out[movie_index][65])\n",
    "\n",
    "print(\"rounded\")\n",
    "print(np.round(out)[movie_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
