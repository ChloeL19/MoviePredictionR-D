{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloeloughridge/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# audio data fed into normalized LSTM with Conv layer\n",
    "\n",
    "\n",
    "# First, import necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting up the keras stuff\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, BatchNormalization, Conv1D, Dropout\n",
    "from keras.layers import LSTM\n",
    "# my custom data_utils file\n",
    "from data_utils_local08 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 207, 1583)\n"
     ]
    }
   ],
   "source": [
    "# uploading the X values\n",
    "#X_input = load_Xinput(get_fc6_directory(7)) #VGG16 data\n",
    "\n",
    "# X_input = np.load('../Desktop/InceptionResNetV2_feature_data.npy') #resnet data!\n",
    "\n",
    "X_input = np.load('../Desktop/audio_feature_data.npy')\n",
    "\n",
    "print(X_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 219)\n"
     ]
    }
   ],
   "source": [
    "# uploading the Y values\n",
    "y_data_input = np.load('../Desktop/labels.npy')\n",
    "print(y_data_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 207, 1583) (4, 207, 1583) (4, 207) (3, 207)\n"
     ]
    }
   ],
   "source": [
    "timesteps = X_input.shape[1]\n",
    "data_dim = X_input.shape[2]\n",
    "\n",
    "X_train = X_input[:4,:timesteps, :]\n",
    "Y_train = y_data_input[:4, :timesteps]\n",
    "\n",
    "X_test = X_input[4:, :timesteps, :]\n",
    "Y_test = y_data_input[4:, :timesteps]\n",
    "\n",
    "print(X_test.shape, X_train.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constructing a many-to-one LSTM model in keras --> inspiration: https://stackoverflow.com/questions/43034960/many-to-one-and-many-to-many-lstm-examples-in-keras\n",
    "# i will start by training a model on only the VGG16 fc6 layer output (that's just one feature)\n",
    "# should I eventually abstract this LSTM model? Create its own object file?\n",
    "model = Sequential()\n",
    "\n",
    "# normalization\n",
    "model.add(BatchNormalization(input_shape=(timesteps, data_dim)))\n",
    "\n",
    "model.add(Conv1D(10, kernel_size=3, activation=\"relu\"))\n",
    "\n",
    "model.add(LSTM(timesteps, return_sequences=True))\n",
    "#input_shape=(timesteps, data_dim)\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(LSTM(timesteps, return_sequences=True))\n",
    "\n",
    "# going to try adding a flatten layer in here\n",
    "model.add(Flatten()) # I got this from a github thing, but I still don't completely understand why it works\n",
    "# add the final dense layer and then softmax\n",
    "model.add(Dense(timesteps, activation='sigmoid'))\n",
    "# going to add a softmax activation to this\n",
    "#model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a new metric of evaluation! the F-score!\n",
    "def FScore2(y_true, y_pred):\n",
    "    '''\n",
    "    The F score, beta=2\n",
    "    '''\n",
    "    B2 = K.variable(4)\n",
    "    OnePlusB2 = K.variable(5)\n",
    "    pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(K.less(K.abs(pred - K.clip(y_true, .5, 1.)), 0.01), 'float32'), -1)\n",
    "    fp = K.sum(K.cast(K.greater(pred - y_true, 0.1), 'float32'), -1)\n",
    "    fn = K.sum(K.cast(K.less(pred - y_true, -0.1), 'float32'), -1)\n",
    "\n",
    "    f2 = OnePlusB2 * tp / (OnePlusB2 * tp + B2 * fn + fp)\n",
    "\n",
    "    return K.mean(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compiling LSTM model\n",
    "# note that Ng used an Adam optimizer and categorical cross-entropy loss\n",
    "# but this is a binary classification problem so I think the parameters below should suffice\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy', FScore2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples, validate on 3 samples\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 3s 747ms/step - loss: 0.6948 - binary_accuracy: 0.4734 - FScore2: 0.2891 - val_loss: 1.3670 - val_binary_accuracy: 0.5507 - val_FScore2: 0.0885\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 286ms/step - loss: 0.9369 - binary_accuracy: 0.6582 - FScore2: 0.2066 - val_loss: 4.4408 - val_binary_accuracy: 0.6248 - val_FScore2: 0.2922\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 344ms/step - loss: 2.1960 - binary_accuracy: 0.8007 - FScore2: 0.5338 - val_loss: 2.2507 - val_binary_accuracy: 0.5233 - val_FScore2: 0.4208\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.6123 - binary_accuracy: 0.5314 - FScore2: 0.3648 - val_loss: 3.6917 - val_binary_accuracy: 0.7021 - val_FScore2: 0.0204\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 1.1203 - binary_accuracy: 0.8490 - FScore2: 0.4444 - val_loss: 4.1692 - val_binary_accuracy: 0.4589 - val_FScore2: 0.3060\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 249ms/step - loss: 2.7237 - binary_accuracy: 0.6739 - FScore2: 0.5251 - val_loss: 2.7771 - val_binary_accuracy: 0.7021 - val_FScore2: 0.0204\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 0.7213 - binary_accuracy: 0.8925 - FScore2: 0.5873 - val_loss: 2.5156 - val_binary_accuracy: 0.6200 - val_FScore2: 0.2909\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 2s 380ms/step - loss: 0.7650 - binary_accuracy: 0.8225 - FScore2: 0.5551 - val_loss: 3.9932 - val_binary_accuracy: 0.6699 - val_FScore2: 0.0399\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 1.2463 - binary_accuracy: 0.8563 - FScore2: 0.4648 - val_loss: 2.2914 - val_binary_accuracy: 0.7021 - val_FScore2: 0.0204\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.4226 - binary_accuracy: 0.8925 - FScore2: 0.5873 - val_loss: 1.8197 - val_binary_accuracy: 0.6216 - val_FScore2: 0.2885\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.2580 - binary_accuracy: 0.8297 - FScore2: 0.5767 - val_loss: 1.8181 - val_binary_accuracy: 0.6731 - val_FScore2: 0.0439\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.2464 - binary_accuracy: 0.8768 - FScore2: 0.5347 - val_loss: 1.6286 - val_binary_accuracy: 0.6248 - val_FScore2: 0.2922\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.2332 - binary_accuracy: 0.8176 - FScore2: 0.5503 - val_loss: 1.7745 - val_binary_accuracy: 0.6699 - val_FScore2: 0.0399\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 0.2504 - binary_accuracy: 0.8563 - FScore2: 0.4501 - val_loss: 1.6329 - val_binary_accuracy: 0.6248 - val_FScore2: 0.2922\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.2641 - binary_accuracy: 0.8261 - FScore2: 0.5544 - val_loss: 1.7030 - val_binary_accuracy: 0.6651 - val_FScore2: 0.0398\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.2525 - binary_accuracy: 0.8563 - FScore2: 0.4681 - val_loss: 1.5077 - val_binary_accuracy: 0.6248 - val_FScore2: 0.2922\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 1s 218ms/step - loss: 0.2573 - binary_accuracy: 0.8249 - FScore2: 0.5615 - val_loss: 1.6140 - val_binary_accuracy: 0.6602 - val_FScore2: 0.0397\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.2450 - binary_accuracy: 0.8611 - FScore2: 0.4772 - val_loss: 1.3933 - val_binary_accuracy: 0.6296 - val_FScore2: 0.2264\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.2449 - binary_accuracy: 0.8104 - FScore2: 0.5113 - val_loss: 1.4963 - val_binary_accuracy: 0.6699 - val_FScore2: 0.0399\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 1s 279ms/step - loss: 0.2372 - binary_accuracy: 0.8587 - FScore2: 0.4568 - val_loss: 1.3660 - val_binary_accuracy: 0.6312 - val_FScore2: 0.2299\n",
      "finished training!\n"
     ]
    }
   ],
   "source": [
    "# running the LSTM model\n",
    "model.fit(X_train, Y_train, epochs = 20, batch_size = 128, validation_data=(X_test, Y_test))\n",
    "print(\"finished training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "save() got an unexpected keyword argument 'include_metric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7996267be9ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./audio_cnn_norm_drop_lstm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: save() got an unexpected keyword argument 'include_metric'"
     ]
    }
   ],
   "source": [
    "model.save('./audio_cnn_norm_drop_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model prediction:\n",
      "[8.73011188e-04 6.73524220e-04 7.57076486e-04 1.19396381e-03\n",
      " 9.97976866e-04 6.59375102e-04 8.29332275e-04 6.85389154e-04\n",
      " 1.01351645e-03 1.10705744e-03 8.16348649e-04 1.13546080e-03\n",
      " 8.59474472e-04 1.04014564e-03 8.94202676e-04 7.48174440e-04\n",
      " 1.21196196e-03 8.05895485e-04 1.22030987e-03 8.38304055e-04\n",
      " 1.15930708e-03 8.40465538e-04 1.07808376e-03 9.90873203e-04\n",
      " 1.19074387e-03 1.12607400e-03 4.87624377e-01 5.11097908e-01\n",
      " 5.19720852e-01 4.96523529e-01 5.17930984e-01 4.92724568e-01\n",
      " 5.02635181e-01 5.02999961e-01 5.19610763e-01 5.00069678e-01\n",
      " 5.01542687e-01 8.48218679e-01 8.41657639e-01 4.88829970e-01\n",
      " 4.96384263e-01 4.82674688e-01 5.11160612e-01 5.14417768e-01\n",
      " 5.10625303e-01 5.15987575e-01 5.10102928e-01 5.04541218e-01\n",
      " 5.08259594e-01 5.08650064e-01 5.13549626e-01 5.11653006e-01\n",
      " 8.83008957e-01 8.33679795e-01 8.62520516e-01 8.65613878e-01\n",
      " 8.61397564e-01 8.76735866e-01 8.73146296e-01 8.35579157e-01\n",
      " 4.97643769e-01 5.01167357e-01 5.00925422e-01 5.08317232e-01\n",
      " 2.03456849e-01 1.83665857e-01 1.37924373e-01 1.41146123e-01\n",
      " 1.37567848e-01 5.17391384e-01 5.12636364e-01 4.99634415e-01\n",
      " 1.52515635e-01 1.35885671e-01 3.28998649e-05 3.85032217e-05\n",
      " 4.10693938e-05 3.35549739e-05 4.80574381e-05 3.62716892e-05\n",
      " 2.00880662e-01 1.12070814e-01 1.37852982e-01 1.29039079e-01\n",
      " 1.25700906e-01 4.14771166e-05 4.22756239e-05 4.05016581e-05\n",
      " 4.17180599e-05 4.11395195e-05 4.08914602e-05 3.94952804e-05\n",
      " 3.74515948e-05 3.90503192e-05 3.35250043e-05 1.35701701e-01\n",
      " 5.17288804e-01 5.05120695e-01 5.22905827e-01 1.47921816e-01\n",
      " 1.35504901e-01 1.43404499e-01 5.12899518e-01 5.02894163e-01\n",
      " 5.15573084e-01 1.36167660e-01 1.39875621e-01 1.24248169e-01\n",
      " 1.29470140e-01 8.75118896e-02 4.96927708e-01 5.15113890e-01\n",
      " 5.07985711e-01 4.90199357e-01 5.09521604e-01 5.13928354e-01\n",
      " 5.03822386e-01 5.12838185e-01 4.98916715e-01 4.97515917e-01\n",
      " 5.14903486e-01 4.96307075e-01 5.18034875e-01 5.06535053e-01\n",
      " 4.98337567e-01 4.97666448e-01 9.05944034e-04 1.29676005e-03\n",
      " 6.24830485e-04 4.57574897e-05 4.07785665e-05 3.59958140e-05\n",
      " 3.78879886e-05 4.98954905e-05 4.80757226e-05 4.08242886e-05\n",
      " 3.72041941e-05 3.85555104e-05 4.84316552e-05 3.80832716e-05\n",
      " 5.13554078e-05 4.03412996e-05 4.93154912e-05 5.44566392e-05\n",
      " 4.11596484e-05 5.07839541e-05 1.00033567e-03 5.88046620e-04\n",
      " 9.10694478e-04 1.15811999e-03 9.21450322e-04 8.27580981e-04\n",
      " 8.40279390e-04 1.01240131e-03 1.08072441e-03 6.93958835e-04\n",
      " 8.05419520e-04 1.01824338e-03 8.85985966e-04 1.06275734e-03\n",
      " 8.54060694e-04 1.07604079e-03 1.06029690e-03 1.04496116e-03\n",
      " 9.64047329e-04 1.14457251e-03 9.85550927e-04 7.71100284e-04\n",
      " 1.19006983e-03 9.95717943e-04 7.23264297e-04 8.83438450e-04\n",
      " 1.62897992e-03 1.12029572e-03 8.34750594e-04 1.31595542e-03\n",
      " 1.06884481e-03 7.96640408e-04 1.10561552e-03 8.85023270e-04\n",
      " 1.13889854e-03 7.74367247e-04 8.79569678e-04 9.38150857e-04\n",
      " 1.01565942e-03 6.01714943e-04 1.05865882e-03 1.26318273e-03\n",
      " 8.23520299e-04 1.33967586e-03 9.40447382e-04 1.06515340e-03\n",
      " 5.26505232e-01 5.03955781e-01 5.06038606e-01 4.91972893e-01\n",
      " 5.03177285e-01 5.61303284e-04 1.16955035e-03 9.68696957e-04\n",
      " 6.48724032e-04 8.66745890e-04 1.04367873e-03 1.34091021e-03\n",
      " 1.31729210e-03 1.09012611e-03 1.09214010e-03]\n",
      "target:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "before 64:\n",
      "0.50831723\n",
      "64:\n",
      "0.18366586\n",
      "rounded\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0.\n",
      " 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# trying to view the model output\n",
    "out = model.predict(X_train)\n",
    "\n",
    "movie_index = 2\n",
    "\n",
    "print(\"model prediction:\")\n",
    "print(out[movie_index])\n",
    "print(\"target:\")\n",
    "print(Y_train[movie_index])\n",
    "\n",
    "print(\"before 64:\")\n",
    "print(out[movie_index][63])\n",
    "print(\"64:\")\n",
    "print(out[movie_index][65])\n",
    "\n",
    "print(\"rounded\")\n",
    "print(np.round(out)[movie_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try visualizing this model at some point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
