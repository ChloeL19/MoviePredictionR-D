{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trying to import cv2\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = np.load('../Desktop/Cloud_Training/data/labels01.npy')\n",
    "VGG = np.load('../Desktop/Cloud_Training/data/VGG16_data01.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 101, 4096)\n",
      "(33, 101)\n",
      "[[[-21.381     -4.8956    -0.2235   ... -18.261      2.2304     9.2675  ]\n",
      "  [-20.597     -8.3136    -0.64991  ... -16.16       1.9758     6.7264  ]\n",
      "  [-12.246     -0.63586    2.1734   ...  -6.4799    -1.834      5.4004  ]\n",
      "  ...\n",
      "  [-16.875     -1.5837    -2.4269   ... -10.449     -0.95816    0.24002 ]\n",
      "  [-19.721      3.5623    -0.57537  ... -10.838      1.6215     0.283   ]\n",
      "  [-18.79       3.405     -0.21461  ... -10.726     -1.0635    -1.1843  ]]\n",
      "\n",
      " [[ -4.8347    -1.0434    -3.3666   ...   2.5202    -6.1011    -7.3908  ]\n",
      "  [ -5.5089    -1.7925    -2.1795   ...   1.7458    -4.904     -3.8956  ]\n",
      "  [ -5.7111    -1.1572    -3.25     ...   1.6239    -5.8648    -3.3789  ]\n",
      "  ...\n",
      "  [-15.874    -10.868     -0.54184  ... -12.469      2.1109     2.9179  ]\n",
      "  [ -1.557      3.23      -7.2674   ...   5.7708     4.2134     3.131   ]\n",
      "  [ -2.102      7.4851    -0.33886  ...   0.92398    3.9576     1.3112  ]]\n",
      "\n",
      " [[ -2.8341     0.19749   -6.4848   ...   3.7212     4.9345     3.4463  ]\n",
      "  [-15.634     -5.5387     7.7001   ... -13.934    -13.149     -4.4762  ]\n",
      "  [ -1.0089     8.3255    -1.9879   ... -11.999      1.8348     9.34    ]\n",
      "  ...\n",
      "  [-10.013     -0.28503    3.2197   ... -10.943     -1.2449     1.3755  ]\n",
      "  [-11.206     -3.3544    -2.2083   ... -10.285     -1.8512    -1.3356  ]\n",
      "  [-12.21      -4.3369     0.3992   ... -11.105     -0.70338   -0.50856 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ -5.44       2.8761     7.7627   ...  -8.7573     1.0714    -0.15357 ]\n",
      "  [ -4.5792     0.64864    1.8932   ... -16.708     -5.0435    -0.062015]\n",
      "  [-13.341     -2.9124     1.0262   ... -14.439     -1.3732     1.5753  ]\n",
      "  ...\n",
      "  [-10.935      1.8946     1.6486   ...   4.9367    -7.1298     6.5882  ]\n",
      "  [-11.317      1.4072    -0.32202  ...   1.823     -5.0657     5.3409  ]\n",
      "  [ -6.5651     2.7077    -2.7128   ...   2.0635    -1.7318     4.7627  ]]\n",
      "\n",
      " [[ -4.8018     1.0151    -3.6487   ...   0.32187   -1.3566    -0.29224 ]\n",
      "  [ -4.9087     0.81089   -3.5088   ...   0.25513   -1.3051    -0.20006 ]\n",
      "  [ -5.498     -8.1854    -7.519    ... -10.193     -9.7879     5.0013  ]\n",
      "  ...\n",
      "  [-11.309     -4.4225     0.96131  ... -12.578     -1.7926    -1.0058  ]\n",
      "  [ -8.3821     1.4589   -10.109    ... -11.021      2.8731     1.9824  ]\n",
      "  [ -9.5424     0.045322  -2.4084   ... -14.7        0.54339    3.7361  ]]\n",
      "\n",
      " [[-10.9        0.39422   -4.9941   ...  -8.8488     5.9144    -0.60794 ]\n",
      "  [-13.172      0.96304   -1.6071   ...  -9.8952     9.2445     1.5774  ]\n",
      "  [-12.743      0.34765   -1.2158   ... -12.6        9.6655     4.503   ]\n",
      "  ...\n",
      "  [-10.293      0.28771   -0.73508  ...   4.3319    -7.4103     3.5409  ]\n",
      "  [-12.913      1.2059    -0.3258   ...   2.077     -4.3053     4.8925  ]\n",
      "  [-12.006      1.2601    -0.39158  ...   3.0474    -3.8012     4.932   ]]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 1.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# selecting only the chunks with fear-inducing segments to train on\n",
    "# first we'll need to reshape the VGG data\n",
    "\n",
    "# we can do this in different ways, maybe first extract fear-inducing from the entire training\n",
    "# and testing sets\n",
    "# next just extract from training set and test on everything (this is much more realistic)\n",
    "X_sendin = []\n",
    "Y_sendin = []\n",
    "count = 0\n",
    "for seg in labels_reshape:\n",
    "    if seg.any() == 1:\n",
    "        X_sendin.append(VGG_reshape[count])\n",
    "        Y_sendin.append(seg)\n",
    "    count += 1\n",
    "    \n",
    "X_input = np.asarray(X_sendin)\n",
    "Y_input = np.asarray(Y_sendin)\n",
    "\n",
    "print(X_input.shape)\n",
    "print(Y_input.shape)\n",
    "print(X_input)\n",
    "print(Y_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 6262)\n",
      "(14, 6262, 4096)\n",
      "[[[ -4.7936    2.6032   -3.5129  ...   1.774     0.9897    3.9134 ]\n",
      "  [ -4.7936    2.6032   -3.5129  ...   1.774     0.9897    3.9134 ]\n",
      "  [ -4.7936    2.6032   -3.5129  ...   1.774     0.9897    3.9134 ]\n",
      "  ...\n",
      "  [  0.        0.        0.      ...   0.        0.        0.     ]\n",
      "  [  0.        0.        0.      ...   0.        0.        0.     ]\n",
      "  [  0.        0.        0.      ...   0.        0.        0.     ]]\n",
      "\n",
      " [[ -4.7936    2.6032   -3.5129  ...   1.774     0.9897    3.9134 ]\n",
      "  [ -4.7936    2.6032   -3.5129  ...   1.774     0.9897    3.9134 ]\n",
      "  [ -4.7936    2.6032   -3.5129  ...   1.774     0.9897    3.9134 ]\n",
      "  ...\n",
      "  [  0.        0.        0.      ...   0.        0.        0.     ]\n",
      "  [  0.        0.        0.      ...   0.        0.        0.     ]\n",
      "  [  0.        0.        0.      ...   0.        0.        0.     ]]\n",
      "\n",
      " [[ -9.5335    1.6831    9.2677  ...  -4.9263   -1.9509    9.9691 ]\n",
      "  [-10.012     1.938     9.9497  ...  -4.1087   -2.9607    9.55   ]\n",
      "  [ -0.03942  -3.1914    9.4291  ... -10.324   -14.621     5.0283 ]\n",
      "  ...\n",
      "  [  0.        0.        0.      ...   0.        0.        0.     ]\n",
      "  [  0.        0.        0.      ...   0.        0.        0.     ]\n",
      "  [  0.        0.        0.      ...   0.        0.        0.     ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ -4.7936    2.6032   -3.5129  ...   1.774     0.9897    3.9134 ]\n",
      "  [ -4.7936    2.6032   -3.5129  ...   1.774     0.9897    3.9134 ]\n",
      "  [ -6.7817   -6.5014   -7.2736  ... -10.289    -5.3276    3.3557 ]\n",
      "  ...\n",
      "  [  0.        0.        0.      ...   0.        0.        0.     ]\n",
      "  [  0.        0.        0.      ...   0.        0.        0.     ]\n",
      "  [  0.        0.        0.      ...   0.        0.        0.     ]]\n",
      "\n",
      " [[ -4.6539    0.20815  -2.9132  ...   0.7552   -2.025     0.10636]\n",
      "  [ -5.0188    0.32979  -3.2875  ...   0.88424  -2.0225    0.27203]\n",
      "  [ -6.9267   -8.4693   -7.6053  ...  -8.9905  -10.122     5.4599 ]\n",
      "  ...\n",
      "  [  0.        0.        0.      ...   0.        0.        0.     ]\n",
      "  [  0.        0.        0.      ...   0.        0.        0.     ]\n",
      "  [  0.        0.        0.      ...   0.        0.        0.     ]]\n",
      "\n",
      " [[ -4.8018    1.0151   -3.6487  ...   0.32187  -1.3566   -0.29224]\n",
      "  [ -4.9087    0.81089  -3.5088  ...   0.25513  -1.3051   -0.20006]\n",
      "  [ -5.498    -8.1854   -7.519   ... -10.193    -9.7879    5.0013 ]\n",
      "  ...\n",
      "  [  0.        0.        0.      ...   0.        0.        0.     ]\n",
      "  [  0.        0.        0.      ...   0.        0.        0.     ]\n",
      "  [  0.        0.        0.      ...   0.        0.        0.     ]]]\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "print(VGG.shape)\n",
    "print(VGG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(868, 101)\n"
     ]
    }
   ],
   "source": [
    "labels_reshape = np.reshape(labels, [868, 101])\n",
    "#VGG_reshape = np.reshape(labels, [868, 101, 4096])\n",
    "\n",
    "print(labels_reshape.shape)\n",
    "#print(VGG_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(868, 101, 4096)\n"
     ]
    }
   ],
   "source": [
    "# splitting up the training data\n",
    "VGG_reshape = np.zeros([868, 101, VGG.shape[2]])\n",
    "mov_count = 0\n",
    "for mov in VGG:\n",
    "    # we will take 62 101-second worth chunks out of the VGG matrix\n",
    "    for i in range(62):\n",
    "        new_mov = mov[i*101:(i+1)*101, :]\n",
    "        VGG_reshape[i + (62*mov_count), :, :] = new_mov\n",
    "        \n",
    "    mov_count +=1\n",
    "    \n",
    "print(VGG_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(VGG_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# undoing the previous function\n",
    "#VGG_normal = np.zeros([14, 6262, 4096])\n",
    "VGG_normal = np.reshape(VGG_reshape, [14, 6262, 4096])\n",
    "print(VGG_normal)\n",
    "if VGG_normal.all() == VGG.all():\n",
    "    print('heck, yeah!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(868, 101)\n"
     ]
    }
   ],
   "source": [
    "# now similarly splitting the labels\n",
    "# splitting up the training data\n",
    "labels_reshape2 = np.zeros([868, 101])\n",
    "mov_count = 0\n",
    "for mov in labels:\n",
    "    # we will take 62 101-second worth chunks out of the labels matrix\n",
    "    for i in range(62):\n",
    "        new_mov = mov[i*101:(i+1)*101]\n",
    "        labels_reshape2[i + (62*mov_count), :] = new_mov\n",
    "        \n",
    "    mov_count +=1\n",
    "    \n",
    "print(labels_reshape2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck, yeah!\n"
     ]
    }
   ],
   "source": [
    "if labels_reshape2.all() == labels_reshape.all():\n",
    "    print(\"truck, yeah!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "double truck yeah!\n"
     ]
    }
   ],
   "source": [
    "if np.reshape(labels_reshape2, [14, 6262]).all() == labels.all():\n",
    "    print(\"double truck yeah!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(868, 101)\n"
     ]
    }
   ],
   "source": [
    "print(labels[0])\n",
    "print(labels_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theres a one in the original at 0\n",
      "theres a one in the original at 1\n",
      "theres a one in the original at 2\n",
      "theres a one in the original at 3\n",
      "theres a one in the original at 4\n",
      "theres a one in the original at 5\n",
      "theres a one in the original at 6\n",
      "theres a one in the original at 7\n",
      "theres a one in the original at 8\n",
      "theres a one in the original at 9\n",
      "theres a one in the original at 10\n",
      "theres a one in the original at 11\n",
      "theres a one in the original at 12\n",
      "theres a one in the original at 13\n",
      "theres a one in the original at 14\n",
      "theres a one in the original at 15\n",
      "theres a one in the original at 16\n",
      "theres a one in the original at 17\n",
      "theres a one in the original at 18\n",
      "theres a one in the original at 19\n",
      "theres a one in the original at 20\n",
      "theres a one in the original at 21\n",
      "theres a one in the original at 22\n",
      "theres a one in the original at 23\n",
      "theres a one in the original at 24\n",
      "theres a one in the original at 25\n",
      "theres a one in the original at 26\n",
      "theres a one in the original at 27\n",
      "theres a one in the original at 28\n",
      "theres a one in the original at 29\n",
      "theres a one in the original at 30\n",
      "theres a one in the original at 31\n",
      "theres a one in the original at 32\n",
      "theres a one in the original at 33\n",
      "theres a one in the original at 34\n",
      "theres a one in the original at 35\n",
      "theres a one in the original at 36\n",
      "theres a one in the original at 37\n",
      "38\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "yey\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for num in labels[0]:\n",
    "    if num==1:\n",
    "        print('theres a one in the original at {}'.format(count))\n",
    "        count +=1\n",
    "    \n",
    "print(count)\n",
    "        \n",
    "#for num in labels_reshape[29]:\n",
    "    #if num==1:\n",
    "        #print('yey')\n",
    "\n",
    "count = 0\n",
    "for num in labels[0]:\n",
    "    #for num in arr:\n",
    "    if num != 0:\n",
    "        print('yey')\n",
    "        count +=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(VGG_reshape[62*6])\n",
    "for arr in VGG_reshape[62*13]:\n",
    "    for num in arr:\n",
    "        if num != 0:\n",
    "            print('yey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this can become get_frame_frm_vid() --> but how to read a specific frame? you can pinpoint one at a given time point\n",
    "print(cv2.__version__)\n",
    "vidcap = cv2.VideoCapture('data_movies/MEDIAEVAL18_07.mp4')\n",
    "success, frame = vidcap.read()\n",
    "print(frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# more messing around with different cv2 functions\n",
    "vidcap = cv2.VideoCapture('data_movies/MEDIAEVAL1_07.mp4')\n",
    "vidcap.open('data_movies/MEDIAEVAL18_07.mp4')\n",
    "is_open = vidcap.isOpened()\n",
    "print(is_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# saving the video frames into local folder for later use --> more experiments\n",
    "\n",
    "# create the video capture object\n",
    "vidcap = cv2.VideoCapture('data_movies/MEDIAEVAL18_07.mp4')\n",
    "\n",
    "#number frames I want to save for testing purposes\n",
    "num_frames = 3\n",
    "count = 0\n",
    "for f in range(num_frames):\n",
    "    success, image = vidcap.read()\n",
    "    cv2.imwrite(\"frame%d.jpg\" % count, image)     # save frame as JPEG file\n",
    "    print('Read a new frame: ', success)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for reading video frames into a file --> source: https://www.life2coding.com/extract-frame-video-file-using-opencv-python/ \n",
    "import cv2\n",
    "import os\n",
    " \n",
    "def extractFrames(pathIn, pathOut):\n",
    "    os.mkdir(pathOut)\n",
    " \n",
    "    cap = cv2.VideoCapture(pathIn)\n",
    "    count = 0\n",
    " \n",
    "    while (cap.isOpened()):\n",
    " \n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    " \n",
    "        if ret == True:\n",
    "            print('Read %d frame: ' % count, ret)\n",
    "            cv2.imwrite(os.path.join(pathOut, \"frame{:d}.jpg\".format(count)), frame)  # save frame as JPEG file\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    " \n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# running the function defined above\n",
    "extractFrames('data_movies/MEDIAEVAL18_07.mp4', 'data_frames/07')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize the frames from the file --> this will eventually be turned into a function\n",
    "\n",
    "# what will become the input arguments of the function:\n",
    "pathOut = 'data_frames/07'\n",
    "\n",
    "# start a counting variable for 100 that controls how many frames are shown\n",
    "count = 1000\n",
    "num_frames = 20\n",
    "\n",
    "for f in range(num_frames):\n",
    "    # create the image file name --> join count with a string, maybe need to use the os thing\n",
    "    img_path = os.path.join(pathOut, \"frame{:d}.jpg\".format(count + f))\n",
    "    # read the image in greyscale using cv2.imread\n",
    "    img = cv2.imread(img_path)\n",
    "    print(img)\n",
    "    print('shape: ', img.shape)\n",
    "    # display the image using cv2.imshow\n",
    "    cv2.imshow('image',img)\n",
    "    cv2.waitKey(0) # wait indefinitely for a keyboard stroke\n",
    "\n",
    "print(\"for-loop completed\")\n",
    "cv2.destroyAllWindows() # destroy the window created\n",
    "print(\"windows destroyed\")\n",
    "\n",
    "# inspiration from here: https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing custom functions from my own data_utils file\n",
    "from data_utils_local01 import extractFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testing these functions\n",
    "extractFrames('data_movies/MEDIAEVAL18_08.mp4', 'data_frames/08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# experimenting with resizing frames\n",
    "import cv2\n",
    "import os\n",
    "from data_utils_local02 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grab a frame from a video\n",
    "frame = get_frm_folder('data_frames/08/frame5033.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize this frame\n",
    "cv2.imshow('img',frame)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape this frame\n",
    "resized_img = cv2.resize(frame, (64,64))\n",
    "# now show it again\n",
    "cv2.imshow('img', resized_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "destroyed the windows\n"
     ]
    }
   ],
   "source": [
    "#cv2.imshow('image',frame)\n",
    "#cv2.waitKey(0) # wait indefinitely for a keyboard stroke"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
