{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloeloughridge/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# normalized VGG feature data concatenated with audio data into simple LSTM\n",
    "\n",
    "\n",
    "# First, import necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting up the keras stuff\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import LSTM\n",
    "# my custom data_utils file\n",
    "from data_utils_local08 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 212, 4096)\n"
     ]
    }
   ],
   "source": [
    "# uploading the X values\n",
    "#X_input = load_Xinput(get_fc6_directory(7)) #VGG16 data\n",
    "\n",
    "X_input = np.load('../Desktop/ResNet50_feature_data.npy')\n",
    "print(X_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212,)\n"
     ]
    }
   ],
   "source": [
    "# uploading the Y values\n",
    "y_data_input = fear_oneHot(212, 'fear_annotations_part01/MEDIAEVAL18_7_Fear.txt')\n",
    "print(y_data_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 212, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Uploading part01 of the local fc6 data\n",
    "\n",
    "timesteps = 212   # the number of seconds in movie 07 --> i will figure out how to programmatically get this value\n",
    "data_dim = 4096    # the number of output values from VGG16 layer fc6 --> switch to programmatic later\n",
    "num_movies = 4\n",
    "batch_size = 7\n",
    "num_epochs = 5\n",
    "validation_num = 3\n",
    "\n",
    "# set up the X_train_data master array\n",
    "X_train_data = np.zeros([num_movies, timesteps, data_dim]) #oooooh this array will have to be as long as the longest\n",
    "                                                            # movie and padded with zeros --> this won't cause problems\n",
    "                                                            # right?\n",
    "X_valid_data = np.zeros([validation_num, timesteps, data_dim])\n",
    "        \n",
    "# for each movie number between and including 7 and 13\n",
    "for num in range(num_movies):\n",
    "    # load the X_input data\n",
    "    X_input = load_Xinput(get_fc6_directory(7 + num))\n",
    "    # put this X_input data into the X_train_data array\n",
    "    X_train_data[num, :, :] = X_input\n",
    "print(X_train_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 212, 4096)\n"
     ]
    }
   ],
   "source": [
    "# loading X validation set\n",
    "X_valid_data = np.zeros([validation_num, timesteps, data_dim])\n",
    "\n",
    "for num in range(validation_num):\n",
    "    # load the X_input data\n",
    "    X_valid = load_Xinput(get_fc6_directory(7 + num_movies + num))\n",
    "    # put this X_input data into the X_train_data array\n",
    "    X_valid_data[num, :, :] = X_valid\n",
    "print(X_valid_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chloeloughridge/AIGrant_LSTMdev\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# uploading the y data\n",
    "\n",
    "# set up y_train_data master array\n",
    "Y_train_data = np.zeros([num_movies, timesteps])\n",
    "\n",
    "# for each movie number between and including 7 and 13\n",
    "for num in range(num_movies):\n",
    "    # create the appropriate path to the fear annotation data\n",
    "    #print(num)\n",
    "    path = os.path.join('fear_annotations_part01/MEDIAEVAL18_{}_Fear.txt'.format(7+num))\n",
    "    # create a one-hot vector\n",
    "    y_data = fear_oneHot(timesteps, path)\n",
    "    # add this one-hot vector to y_train_data\n",
    "    Y_train_data[num, :] = y_data\n",
    "print(Y_train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# upload the Y validation set\n",
    "Y_valid_data = np.zeros([validation_num, timesteps])\n",
    "\n",
    "# for each movie number in validation set\n",
    "for num in range(validation_num):\n",
    "    # create the appropriate path to the fear annotation data\n",
    "    #print(num)\n",
    "    path = os.path.join('fear_annotations_part01/MEDIAEVAL18_{}_Fear.txt'.format(7+ num_movies + num))\n",
    "    # create a one-hot vector\n",
    "    y_valid = fear_oneHot(timesteps, path)\n",
    "    # add this one-hot vector to y_train_data\n",
    "    Y_valid_data[num, :] = y_valid\n",
    "print(Y_valid_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constructing a many-to-one LSTM model in keras --> inspiration: https://stackoverflow.com/questions/43034960/many-to-one-and-many-to-many-lstm-examples-in-keras\n",
    "# i will start by training a model on only the VGG16 fc6 layer output (that's just one feature)\n",
    "# should I eventually abstract this LSTM model? Create its own object file?\n",
    "model = Sequential()\n",
    "\n",
    "# normalization\n",
    "model.add(BatchNormalization(input_shape=(timesteps, data_dim)))\n",
    "\n",
    "model.add(LSTM(212, return_sequences=True))\n",
    "#input_shape=(timesteps, data_dim)\n",
    "\n",
    "# going to try adding a flatten layer in here\n",
    "model.add(Flatten()) # I got this from a github thing, but I still don't completely understand why it works\n",
    "# add the final dense layer and then softmax\n",
    "model.add(Dense(212, activation='sigmoid'))\n",
    "# going to add a softmax activation to this\n",
    "#model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a new metric of evaluation! the F-score!\n",
    "def FScore2(y_true, y_pred):\n",
    "    '''\n",
    "    The F score, beta=2\n",
    "    '''\n",
    "    B2 = K.variable(4)\n",
    "    OnePlusB2 = K.variable(5)\n",
    "    pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(K.less(K.abs(pred - K.clip(y_true, .5, 1.)), 0.01), 'float32'), -1)\n",
    "    fp = K.sum(K.cast(K.greater(pred - y_true, 0.1), 'float32'), -1)\n",
    "    fn = K.sum(K.cast(K.less(pred - y_true, -0.1), 'float32'), -1)\n",
    "\n",
    "    f2 = OnePlusB2 * tp / (OnePlusB2 * tp + B2 * fn + fp)\n",
    "\n",
    "    return K.mean(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compiling LSTM model\n",
    "# note that Ng used an Adam optimizer and categorical cross-entropy loss\n",
    "# but this is a binary classification problem so I think the parameters below should suffice\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy', FScore2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples, validate on 3 samples\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.7303 - binary_accuracy: 0.4847 - FScore2: 0.2761 - val_loss: 0.8384 - val_binary_accuracy: 0.6525 - val_FScore2: 0.1889\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 3s 846ms/step - loss: 0.0043 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 0.9081 - val_binary_accuracy: 0.6792 - val_FScore2: 0.1555\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 3s 836ms/step - loss: 7.4158e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.1098 - val_binary_accuracy: 0.6494 - val_FScore2: 0.2210\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 3s 840ms/step - loss: 2.5083e-05 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.1106 - val_binary_accuracy: 0.6494 - val_FScore2: 0.2210\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 3s 835ms/step - loss: 1.6161e-05 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.1124 - val_binary_accuracy: 0.6557 - val_FScore2: 0.2225\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 3s 825ms/step - loss: 1.4562e-05 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.1143 - val_binary_accuracy: 0.6588 - val_FScore2: 0.2225\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 3s 832ms/step - loss: 1.3337e-05 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.1161 - val_binary_accuracy: 0.6619 - val_FScore2: 0.2233\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 4s 904ms/step - loss: 1.2313e-05 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.1180 - val_binary_accuracy: 0.6651 - val_FScore2: 0.2237\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 4s 900ms/step - loss: 1.1437e-05 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.1199 - val_binary_accuracy: 0.6667 - val_FScore2: 0.2241\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 3s 845ms/step - loss: 1.0680e-05 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.1217 - val_binary_accuracy: 0.6667 - val_FScore2: 0.2241\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 3s 846ms/step - loss: 1.0014e-05 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.1235 - val_binary_accuracy: 0.6667 - val_FScore2: 0.2241\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 4s 885ms/step - loss: 9.4228e-06 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.1253 - val_binary_accuracy: 0.6682 - val_FScore2: 0.2241\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 3s 829ms/step - loss: 8.8888e-06 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.1271 - val_binary_accuracy: 0.6714 - val_FScore2: 0.2249\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 3s 847ms/step - loss: 8.4052e-06 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.1289 - val_binary_accuracy: 0.6761 - val_FScore2: 0.2256\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 3s 832ms/step - loss: 7.9630e-06 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.1307 - val_binary_accuracy: 0.6761 - val_FScore2: 0.2256\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 4s 892ms/step - loss: 7.5583e-06 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.1324 - val_binary_accuracy: 0.6792 - val_FScore2: 0.2260\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 3s 822ms/step - loss: 7.1844e-06 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.1342 - val_binary_accuracy: 0.6792 - val_FScore2: 0.2260\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 3s 824ms/step - loss: 6.8364e-06 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.1360 - val_binary_accuracy: 0.6777 - val_FScore2: 0.2256\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 3s 828ms/step - loss: 6.5134e-06 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.1379 - val_binary_accuracy: 0.6777 - val_FScore2: 0.2256\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 3s 872ms/step - loss: 6.2116e-06 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.1397 - val_binary_accuracy: 0.6761 - val_FScore2: 0.2253\n",
      "finished training!\n"
     ]
    }
   ],
   "source": [
    "# running the LSTM model\n",
    "model.fit(X_train_data, Y_train_data, epochs = 20, validation_data=(X_valid_data, Y_valid_data))\n",
    "print(\"finished training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model prediction:\n",
      "[1.54748250e-05 3.73860348e-06 6.22802236e-06 6.84977522e-06\n",
      " 5.97175756e-07 6.51306891e-06 9.21828178e-06 4.08543929e-06\n",
      " 3.54271606e-06 4.45281330e-06 1.05653760e-06 1.66419741e-05\n",
      " 5.98137831e-06 7.53025142e-06 9.62440481e-06 2.18011792e-07\n",
      " 6.78542847e-06 4.69344695e-06 1.29463770e-05 1.11682666e-05\n",
      " 2.12881332e-05 1.12767366e-05 1.87479200e-05 3.29778686e-07\n",
      " 1.18505579e-06 1.20513505e-06 2.08084548e-05 1.91864228e-06\n",
      " 1.13845972e-05 3.08246649e-06 1.25656243e-06 8.62167599e-06\n",
      " 6.54126438e-07 1.17486788e-05 1.34551519e-05 2.64658092e-06\n",
      " 2.64688128e-06 8.37437995e-08 1.31720908e-05 1.16092569e-05\n",
      " 5.34302490e-06 1.08353806e-05 5.57745625e-06 4.13202042e-06\n",
      " 8.79331492e-06 4.44126954e-06 5.46432875e-06 5.91790376e-06\n",
      " 1.39598424e-05 1.18559842e-06 6.46799833e-07 2.81252378e-05\n",
      " 5.32632248e-06 1.97402642e-05 2.62943504e-05 7.93019990e-06\n",
      " 1.48234894e-05 3.32322852e-05 6.08982918e-06 3.26837471e-05\n",
      " 1.08267659e-05 6.69205247e-06 2.06846398e-05 2.52684003e-07\n",
      " 9.99953151e-01 9.99996901e-01 9.99986529e-01 9.99978423e-01\n",
      " 9.99985576e-01 9.99992013e-01 9.99987125e-01 9.99997139e-01\n",
      " 9.99995470e-01 9.99998450e-01 9.99997616e-01 9.99994040e-01\n",
      " 9.99995589e-01 9.99993563e-01 9.99998927e-01 9.99995828e-01\n",
      " 9.99999762e-01 9.99996662e-01 9.99979734e-01 9.99998689e-01\n",
      " 1.00000000e+00 9.99993563e-01 9.99996543e-01 9.99997020e-01\n",
      " 9.99999285e-01 1.00000000e+00 1.00000000e+00 9.99999642e-01\n",
      " 9.99998093e-01 9.99998212e-01 9.99994516e-01 9.99966025e-01\n",
      " 9.99989629e-01 9.99990940e-01 9.99980927e-01 9.99996543e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.54904610e-05 1.34784359e-05\n",
      " 4.22378389e-06 9.99992847e-01 9.99998569e-01 9.99964714e-01\n",
      " 9.99996781e-01 9.99979973e-01 7.56223289e-06 7.76241995e-06\n",
      " 2.43570707e-06 3.02486796e-06 8.03208422e-07 4.33120294e-06\n",
      " 5.10107100e-07 1.89716843e-06 1.16963938e-05 4.10620117e-07\n",
      " 2.89099694e-06 2.55170562e-06 3.03754109e-06 3.10518008e-05\n",
      " 1.21813082e-06 5.18629577e-07 1.94863173e-06 1.21644757e-06\n",
      " 1.10794633e-06 9.99996901e-01 9.99998569e-01 9.99997020e-01\n",
      " 9.99995947e-01 9.99995470e-01 9.99996901e-01 9.99998093e-01\n",
      " 9.99998212e-01 9.99996066e-01 9.99995112e-01 9.99997854e-01\n",
      " 9.99999285e-01 1.00000000e+00 9.99997735e-01 9.99987602e-01\n",
      " 9.99999881e-01 9.99998808e-01 2.57597803e-05 1.33850554e-05\n",
      " 1.88570484e-05 1.22658585e-05 3.28209399e-06 1.85118938e-06\n",
      " 4.01300485e-06 8.29957480e-06 8.26079577e-06 1.40481029e-06\n",
      " 1.52366274e-05 7.81937797e-06 2.14381398e-05 4.96036455e-06\n",
      " 3.57272256e-06 8.57785653e-06 1.91800464e-05 2.54776614e-06\n",
      " 3.30948910e-06 6.96207690e-06 1.73385870e-05 6.89834508e-07\n",
      " 1.79513754e-05 8.07614924e-06 1.38269968e-06 3.12778207e-06\n",
      " 8.11341215e-06 1.30388480e-05 8.14731902e-06 1.12514590e-05\n",
      " 8.67424387e-06 8.30527642e-06 2.25668850e-06 1.64882185e-05\n",
      " 6.98436133e-06 1.32271743e-05 4.06441131e-06 1.49194320e-05\n",
      " 3.02417857e-06 7.99232748e-06 6.64760319e-06 1.16048632e-05\n",
      " 1.50377730e-06 1.42331459e-07 7.94981133e-06 7.99610189e-06\n",
      " 2.19718413e-06 3.94940298e-06 2.74062240e-05 7.00223472e-06\n",
      " 7.06066112e-06 1.98481098e-06 1.34632128e-05 1.11165609e-05\n",
      " 1.56078295e-05 1.63009172e-05 2.12337545e-05 1.19745391e-05\n",
      " 1.08770100e-05 5.57755072e-07 1.02460181e-05 2.12628109e-07\n",
      " 4.78467473e-06 1.41298221e-06 1.78009543e-07 7.29976227e-06]\n",
      "target:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "before 64:\n",
      "2.52684e-07\n",
      "64:\n",
      "0.9999969\n",
      "rounded\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# trying to view the model output\n",
    "out = model.predict(X_train_data)\n",
    "print(\"model prediction:\")\n",
    "print(out[0])\n",
    "print(\"target:\")\n",
    "print(Y_train_data[0])\n",
    "\n",
    "print(\"before 64:\")\n",
    "print(out[0][63])\n",
    "print(\"64:\")\n",
    "print(out[0][65])\n",
    "\n",
    "print(\"rounded\")\n",
    "print(np.round(out)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try visualizing this model at some point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
