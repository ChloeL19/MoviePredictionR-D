{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here is the code for generating the feature and label matrices!\n",
    "\n",
    "# IMPORTING THE BACKGROUND STUFF\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os, math, csv\n",
    "from keras.models import Model\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# A helper function for later down the road --> for converting fear annotations to one-hot vectors\n",
    "def fear_oneHot(movie_length, fear_path):\n",
    "    # load start and end times from file\n",
    "    y_data = np.loadtxt(fear_path, skiprows=1)\n",
    "    y_data_input = np.zeros((movie_length))\n",
    "    \n",
    "    # need to address corner case if y_data is 1D array\n",
    "    if type(y_data[0]) == np.float64:\n",
    "        y_data_ext = np.zeros([1,2])\n",
    "        y_data_ext[:,:] = np.asarray(y_data)\n",
    "    else:\n",
    "        y_data_ext = y_data \n",
    "        \n",
    "          \n",
    "    # for each element in first dimension of the y_data array\n",
    "    for i in range(y_data_ext.shape[0]):\n",
    "        # access the start time number and end time number\n",
    "        start = int(y_data_ext[i][0])\n",
    "        end = int(y_data_ext[i][1])\n",
    "        # set the elements between these indices in the zeros array to one\n",
    "        y_data_input[start] = 1 #maybe superfluous\n",
    "        y_data_input[end] = 1\n",
    "        y_data_input[start:end] = 1\n",
    "        \n",
    "    return y_data_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FOR LOADING THE VGG16 DATA\n",
    "\n",
    "VGG_data_dim = 4096\n",
    "timesteps= 5564 # the max number of timesteps --> note that the movies have different lengths\n",
    "num_movies = #TODO - THE NUMBER OF MOVIES IN THE FOLDER NEEDS TO BE CONFIRMED FOR EACH DEVSET\n",
    "VGG16_feature_data = np.zeros([num_movies, timesteps, VGG_data_dim])\n",
    "\n",
    "# for each movie\n",
    "for num in range(num_movies):\n",
    "    # load the X_input data\n",
    "    # get the file path\n",
    "    mov = 54 + num # TODO - MAY BE NECESSARY TO ADD A CONSTANT IN ORDER TO GET CORRECT MOVIE NUMBER\n",
    "    # TODO - PLEASE CONFIRM FILE PATH\n",
    "    path = os.path.join('/Users/chloeloughridge/Desktop/MEDIAEVAL18-TestSet-Visual_features/visual_features/MEDIAEVAL18_{}/fc6'.format(mov))\n",
    "    count = 0\n",
    "    # loading the VGG16 feature data from each file in the folder\n",
    "    for file in os.listdir(path):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".txt\"):\n",
    "            input_data = np.loadtxt(os.path.join(path, file), delimiter=',')\n",
    "            VGG16_feature_data[num, count, :] = np.asarray(input_data)[:]\n",
    "            count = count + 1\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "    print(num)\n",
    "            \n",
    "print(count)\n",
    "print(VGG16_feature_data.shape)\n",
    "print(VGG16_feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SAVING THE VGG16 FEATURE DATA\n",
    "\n",
    "file_name = None # TODO - Maybe something like VGG_feature_data01 for devset part 1?\n",
    "path = None # TODO - path for saving the file\n",
    "np.save(file_name, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FOR CREATING THE LABELS MATRIX\n",
    "\n",
    "# please download Fear Annotations from Liris Accede dataset\n",
    "\n",
    "labels_matrix = np.zeros([num_movies, timesteps])\n",
    "\n",
    "for num in range(num_movies):\n",
    "    # create the appropriate path to the fear annotation data\n",
    "    # TODO - PLEASE CONFIRM THESE ARE THE CORRECT PATHS\n",
    "    if num < 10:\n",
    "        path = os.path.join('/Users/chloeloughridge/Desktop/AI Grant Project/Dataset/2018 Task Data/MEDIAEVAL18-DevSet-Part1-Fear-annotations/annotations/MEDIAEVAL18_0{}_Fear.txt'.format(num))\n",
    "    if num > 10:\n",
    "        path = os.path.join('/Users/chloeloughridge/Desktop/AI Grant Project/Dataset/2018 Task Data/MEDIAEVAL18-DevSet-Part1-Fear-annotations/annotations/MEDIAEVAL18_{}_Fear.txt'.format(num))\n",
    "    # create a one-hot vector\n",
    "    y_data = fear_oneHot(timesteps, path)\n",
    "    # add this one-hot vector to y_train_data\n",
    "    labels_matrix[num, :] = y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SAVING THE LABELS MATRIX\n",
    "\n",
    "file_name = None # TODO - Maybe something like labels01 for devset part 1?\n",
    "path = None # TODO - path for saving the file\n",
    "np.save(file_name, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GENERATING RESNET50 FEATURE DATA\n",
    "\n",
    "# The following code assumes that 1 frame per second from each movie has been saved to a folder on Desktop\n",
    "# called \"frames\". Within \"frames\" I created a numbered folder for each movie.\n",
    "\n",
    "# I ran the following terminal command for each movie to extract one frame per second\n",
    "# the downside is that I then had to rerun this command for each movie in the dataset (and tweak the destination path\n",
    "# accordingly). Perhaps there is a better way?\n",
    "\n",
    "# Here is the command: \n",
    "# ffmpeg -loglevel error -i [MOVIE NAME].mp4 -r 1 -f [DESTINATION PATH] frame-%05d.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FOR GENERATING RESNET50 FEATURE DATA\n",
    "\n",
    "# import pretrained InceptionV3 model from keras\n",
    "model = InceptionV3(include_top=False, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GENERATING RESNET50 FEATURE DATA CONTINUED\n",
    "# iterate though each movie in the folder\n",
    "\n",
    "num_movies = # TODO - however many movies are in this section of the dataset\n",
    "\n",
    "# set up master array\n",
    "inception_v3_feature_data = np.zeros([num_movies, timesteps, 248832]) # TODO - this last number may be wrong; keras \n",
    "# will probably throw an enlightening error if this is the case\n",
    "\n",
    "for num in range(num_movies):\n",
    "    count = 0\n",
    "    for file in os.listdir('../Desktop/frames/{}/'.format(num)):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            # extract the image data\n",
    "            test_img = cv2.imread(os.path.join('../Desktop/frames/{}/'.format(num), filename))\n",
    "            data = (test_img/255)[np.newaxis, :, :, :]\n",
    "            # send image data through the resnet model\n",
    "            intermediate_output = model.predict(data)\n",
    "            # reshape model output\n",
    "            feature_data = intermediate_output.flatten()\n",
    "            # slot into the master away\n",
    "            inception_v3_feature_data[num, count, :] = feature_data\n",
    "        \n",
    "            count = count + 1\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SAVE THE RESNET50 FEATURE DATA\n",
    "filename = #TODO\n",
    "path = # TODO\n",
    "np.save(filename, path)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
