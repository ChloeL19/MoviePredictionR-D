{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This version uses abstracted functions that actually work to load X and Y training data into arrays of the right shape\n",
    "# data successfully flows through LSTM connected to a flatten and dense layer\n",
    "# this version is trained on all of part 1 data and the model is saved in a local file\n",
    "\n",
    "# Here I will be building out the architecture of the first classification LSTM\n",
    "# At each time step, this LSTM will take in a vector representing the extracted audio and visual features from Liris-ACCEDE\n",
    "# Its goal is to output whether or not the movie induces fear at each time step\n",
    "\n",
    "\n",
    "# First, import necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting up the keras stuff\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import LSTM, Conv1D\n",
    "# my custom data_utils file\n",
    "from data_utils_local08 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 4096)\n"
     ]
    }
   ],
   "source": [
    "# uploading the X values\n",
    "X_input = load_Xinput(get_fc6_directory(7))\n",
    "print(X_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212,)\n"
     ]
    }
   ],
   "source": [
    "# uploading the Y values\n",
    "y_data_input = fear_oneHot(212, 'fear_annotations_part01/MEDIAEVAL18_7_Fear.txt')\n",
    "print(y_data_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 212, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Uploading part01 of the local fc6 data\n",
    "\n",
    "timesteps = 212   # the number of seconds in movie 07 --> i will figure out how to programmatically get this value\n",
    "data_dim = 4096    # the number of output values from VGG16 layer fc6 --> switch to programmatic later\n",
    "num_movies = 4\n",
    "batch_size = 7\n",
    "num_epochs = 5\n",
    "validation_num = 3\n",
    "\n",
    "# set up the X_train_data master array\n",
    "X_train_data = np.zeros([num_movies, timesteps, data_dim]) #oooooh this array will have to be as long as the longest\n",
    "                                                            # movie and padded with zeros --> this won't cause problems\n",
    "                                                            # right?\n",
    "X_valid_data = np.zeros([validation_num, timesteps, data_dim])\n",
    "        \n",
    "# for each movie number between and including 7 and 13\n",
    "for num in range(num_movies):\n",
    "    # load the X_input data\n",
    "    X_input = load_Xinput(get_fc6_directory(7 + num))\n",
    "    # put this X_input data into the X_train_data array\n",
    "    X_train_data[num, :, :] = X_input\n",
    "print(X_train_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 212, 4096)\n"
     ]
    }
   ],
   "source": [
    "# loading X validation set\n",
    "X_valid_data = np.zeros([validation_num, timesteps, data_dim])\n",
    "\n",
    "for num in range(validation_num):\n",
    "    # load the X_input data\n",
    "    X_valid = load_Xinput(get_fc6_directory(7 + num_movies + num))\n",
    "    # put this X_input data into the X_train_data array\n",
    "    X_valid_data[num, :, :] = X_valid\n",
    "print(X_valid_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# uploading the y data\n",
    "\n",
    "# set up y_train_data master array\n",
    "Y_train_data = np.zeros([num_movies, timesteps])\n",
    "\n",
    "# for each movie number between and including 7 and 13\n",
    "for num in range(num_movies):\n",
    "    # create the appropriate path to the fear annotation data\n",
    "    #print(num)\n",
    "    path = os.path.join('fear_annotations_part01/MEDIAEVAL18_{}_Fear.txt'.format(7+num))\n",
    "    # create a one-hot vector\n",
    "    y_data = fear_oneHot(timesteps, path)\n",
    "    # add this one-hot vector to y_train_data\n",
    "    Y_train_data[num, :] = y_data\n",
    "print(Y_train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# upload the Y validation set\n",
    "Y_valid_data = np.zeros([validation_num, timesteps])\n",
    "\n",
    "# for each movie number in validation set\n",
    "for num in range(validation_num):\n",
    "    # create the appropriate path to the fear annotation data\n",
    "    #print(num)\n",
    "    path = os.path.join('fear_annotations_part01/MEDIAEVAL18_{}_Fear.txt'.format(7+ num_movies + num))\n",
    "    # create a one-hot vector\n",
    "    y_valid = fear_oneHot(timesteps, path)\n",
    "    # add this one-hot vector to y_train_data\n",
    "    Y_valid_data[num, :] = y_valid\n",
    "print(Y_valid_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constructing a many-to-one LSTM model in keras --> inspiration: https://stackoverflow.com/questions/43034960/many-to-one-and-many-to-many-lstm-examples-in-keras\n",
    "# i will start by training a model on only the VGG16 fc6 layer output (that's just one feature)\n",
    "# should I eventually abstract this LSTM model? Create its own object file?\n",
    "model = Sequential()\n",
    "\n",
    "# add a convolutional layer over here\n",
    "model.add(Conv1D(10, kernel_size=3, activation=\"relu\", input_shape=(timesteps, data_dim)))\n",
    "\n",
    "model.add(LSTM(212, return_sequences=True))\n",
    "\n",
    "# going to try adding a flatten layer in here\n",
    "model.add(Flatten()) # I got this from a github thing, but I still don't completely understand why it works\n",
    "\n",
    "# add the final dense layer and then softmax\n",
    "model.add(Dense(212, activation='sigmoid'))\n",
    "# going to add a softmax activation to this\n",
    "#model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a new metric of evaluation! the F-score!\n",
    "def FScore2(y_true, y_pred):\n",
    "    '''\n",
    "    The F score, beta=2\n",
    "    '''\n",
    "    B2 = K.variable(4)\n",
    "    OnePlusB2 = K.variable(5)\n",
    "    pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(K.less(K.abs(pred - K.clip(y_true, .5, 1.)), 0.01), 'float32'), -1)\n",
    "    fp = K.sum(K.cast(K.greater(pred - y_true, 0.1), 'float32'), -1)\n",
    "    fn = K.sum(K.cast(K.less(pred - y_true, -0.1), 'float32'), -1)\n",
    "\n",
    "    f2 = OnePlusB2 * tp / (OnePlusB2 * tp + B2 * fn + fp)\n",
    "\n",
    "    return K.mean(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compiling LSTM model\n",
    "# note that Ng used an Adam optimizer and categorical cross-entropy loss\n",
    "# but this is a binary classification problem so I think the parameters below should suffice\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy', FScore2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples, validate on 3 samples\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0046 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.9212 - val_binary_accuracy: 0.7028 - val_FScore2: 0.0768\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 212ms/step - loss: 0.0042 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.9331 - val_binary_accuracy: 0.7028 - val_FScore2: 0.0768\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0039 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.9444 - val_binary_accuracy: 0.7028 - val_FScore2: 0.0768\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.0036 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.9552 - val_binary_accuracy: 0.7028 - val_FScore2: 0.0768\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.0033 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.9662 - val_binary_accuracy: 0.7044 - val_FScore2: 0.0770\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0031 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.9767 - val_binary_accuracy: 0.7044 - val_FScore2: 0.0770\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0028 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.9866 - val_binary_accuracy: 0.7028 - val_FScore2: 0.0733\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.0026 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 1.9961 - val_binary_accuracy: 0.6997 - val_FScore2: 0.0659\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.0024 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.0060 - val_binary_accuracy: 0.6997 - val_FScore2: 0.0659\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.0022 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.0161 - val_binary_accuracy: 0.6997 - val_FScore2: 0.0659\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.0020 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.0258 - val_binary_accuracy: 0.6965 - val_FScore2: 0.0584\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 1s 161ms/step - loss: 0.0019 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.0349 - val_binary_accuracy: 0.6965 - val_FScore2: 0.0584\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0017 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.0433 - val_binary_accuracy: 0.6965 - val_FScore2: 0.0584\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0016 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.0517 - val_binary_accuracy: 0.6965 - val_FScore2: 0.0584\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.0015 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.0604 - val_binary_accuracy: 0.6965 - val_FScore2: 0.0584\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 1s 191ms/step - loss: 0.0014 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.0686 - val_binary_accuracy: 0.6965 - val_FScore2: 0.0584\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.0013 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.0769 - val_binary_accuracy: 0.6965 - val_FScore2: 0.0584\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 1s 202ms/step - loss: 0.0012 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.0853 - val_binary_accuracy: 0.6965 - val_FScore2: 0.0584\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.0011 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.0935 - val_binary_accuracy: 0.6965 - val_FScore2: 0.0584\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 1s 156ms/step - loss: 0.0010 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.1021 - val_binary_accuracy: 0.6965 - val_FScore2: 0.0584\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 9.4480e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.1114 - val_binary_accuracy: 0.6965 - val_FScore2: 0.0584\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 8.7579e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.1220 - val_binary_accuracy: 0.6965 - val_FScore2: 0.0584\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 8.0710e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.1325 - val_binary_accuracy: 0.6965 - val_FScore2: 0.0584\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 7.4360e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.1429 - val_binary_accuracy: 0.6965 - val_FScore2: 0.0584\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 6.8632e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.1531 - val_binary_accuracy: 0.6965 - val_FScore2: 0.0584\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 6.3396e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.1621 - val_binary_accuracy: 0.6965 - val_FScore2: 0.0584\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 5.8901e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.1692 - val_binary_accuracy: 0.6965 - val_FScore2: 0.0584\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 5.5199e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.1757 - val_binary_accuracy: 0.6965 - val_FScore2: 0.0584\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 5.1903e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.1821 - val_binary_accuracy: 0.6981 - val_FScore2: 0.0585\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 4.8871e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.1885 - val_binary_accuracy: 0.6981 - val_FScore2: 0.0585\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 4.6051e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.1952 - val_binary_accuracy: 0.6981 - val_FScore2: 0.0585\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 4.3411e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.2015 - val_binary_accuracy: 0.6981 - val_FScore2: 0.0585\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 4.0934e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.2085 - val_binary_accuracy: 0.6981 - val_FScore2: 0.0585\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 3.8604e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.2149 - val_binary_accuracy: 0.6981 - val_FScore2: 0.0585\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 1s 198ms/step - loss: 3.6408e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.2217 - val_binary_accuracy: 0.6981 - val_FScore2: 0.0585\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 3.4336e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.2286 - val_binary_accuracy: 0.6981 - val_FScore2: 0.0585\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 3.2387e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.2356 - val_binary_accuracy: 0.6981 - val_FScore2: 0.0585\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 3.0539e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.2426 - val_binary_accuracy: 0.6981 - val_FScore2: 0.0585\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 2.8799e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.2496 - val_binary_accuracy: 0.6981 - val_FScore2: 0.0585\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 1s 161ms/step - loss: 2.7149e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.2566 - val_binary_accuracy: 0.6981 - val_FScore2: 0.0585\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 2.5573e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.2635 - val_binary_accuracy: 0.6981 - val_FScore2: 0.0585\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 2.4024e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.2710 - val_binary_accuracy: 0.6981 - val_FScore2: 0.0585\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 2.2561e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.2784 - val_binary_accuracy: 0.6997 - val_FScore2: 0.0585\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 2.1188e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.2859 - val_binary_accuracy: 0.6997 - val_FScore2: 0.0585\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 1s 179ms/step - loss: 1.9887e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.2937 - val_binary_accuracy: 0.6997 - val_FScore2: 0.0585\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 1.8660e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.3015 - val_binary_accuracy: 0.6997 - val_FScore2: 0.0585\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 1.7547e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.3098 - val_binary_accuracy: 0.6981 - val_FScore2: 0.0548\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 1.6437e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.3179 - val_binary_accuracy: 0.6981 - val_FScore2: 0.0548\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 1s 187ms/step - loss: 1.5354e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.3271 - val_binary_accuracy: 0.6981 - val_FScore2: 0.0548\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 1.4216e-04 - binary_accuracy: 1.0000 - FScore2: 1.0000 - val_loss: 2.3379 - val_binary_accuracy: 0.6981 - val_FScore2: 0.0548\n",
      "finished training!\n"
     ]
    }
   ],
   "source": [
    "# running the LSTM model\n",
    "model.fit(X_train_data, Y_train_data, epochs = 50, validation_data=(X_valid_data, Y_valid_data))\n",
    "print(\"finished training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model prediction:\n",
      "[1.58757117e-04 5.65342561e-05 6.93871916e-05 9.36704746e-05\n",
      " 2.05786091e-05 1.35061142e-04 1.46761318e-04 8.88979703e-05\n",
      " 8.49307398e-05 4.90488601e-05 7.02822072e-05 5.13327359e-05\n",
      " 1.21120866e-04 4.03712647e-06 4.37390408e-05 9.73372735e-05\n",
      " 9.14012999e-05 1.93071930e-04 6.93227703e-05 9.73926071e-05\n",
      " 6.34244352e-05 1.31032415e-04 1.38340198e-04 1.01213773e-04\n",
      " 8.40352950e-05 7.51984262e-05 4.44619945e-04 9.96925402e-04\n",
      " 4.24151542e-04 4.02316859e-04 4.37093113e-05 8.88102732e-05\n",
      " 3.79306119e-04 2.04113615e-03 2.29448087e-05 3.79092642e-04\n",
      " 3.23549611e-05 1.28209433e-02 1.24152517e-02 7.24724552e-04\n",
      " 2.31764209e-03 6.69773202e-04 7.33688939e-04 8.49537464e-05\n",
      " 5.54204627e-04 5.04970434e-04 5.53619640e-04 7.17733870e-04\n",
      " 4.69983643e-04 3.64973275e-05 7.36893271e-04 1.41977950e-03\n",
      " 1.01963375e-02 8.13827291e-03 3.08922795e-03 7.45249121e-03\n",
      " 1.05979629e-02 1.30151231e-02 9.43313446e-03 7.21332477e-03\n",
      " 5.23011375e-04 7.03895639e-04 4.68040002e-04 6.43996405e-04\n",
      " 9.75241721e-01 9.75555062e-01 9.78508115e-01 9.66954768e-01\n",
      " 9.77224886e-01 9.83708560e-01 9.86132264e-01 9.83097315e-01\n",
      " 9.92807508e-01 9.90770698e-01 9.80812848e-01 9.82758343e-01\n",
      " 9.77738023e-01 9.78645980e-01 9.86361146e-01 9.72557485e-01\n",
      " 9.86568332e-01 9.90329742e-01 9.87557292e-01 9.94211972e-01\n",
      " 9.88779187e-01 9.85908091e-01 9.77347076e-01 9.91726279e-01\n",
      " 9.81005013e-01 9.74018097e-01 9.85708833e-01 9.90604222e-01\n",
      " 9.80740845e-01 9.88924921e-01 9.87940431e-01 9.84411359e-01\n",
      " 9.88436580e-01 9.83700931e-01 9.82224643e-01 9.82601881e-01\n",
      " 9.71937597e-01 9.84171569e-01 2.16598879e-03 6.57303666e-04\n",
      " 4.97170317e-04 9.71530378e-01 9.74768817e-01 9.80403960e-01\n",
      " 9.74249780e-01 9.73483980e-01 7.13562476e-05 1.01269607e-03\n",
      " 6.81891746e-04 6.22310268e-04 6.93231763e-04 6.85465871e-04\n",
      " 1.06651406e-03 3.98355856e-04 1.77024704e-05 3.37453530e-04\n",
      " 5.04125666e-04 7.27717066e-04 5.02422685e-04 2.52260565e-04\n",
      " 2.10619438e-03 8.01291084e-04 1.31259265e-04 4.30114233e-05\n",
      " 7.05676357e-05 9.75164950e-01 9.79605436e-01 9.81028378e-01\n",
      " 9.80740309e-01 9.80481923e-01 9.84638989e-01 9.87360418e-01\n",
      " 9.78737235e-01 9.72126186e-01 9.81234610e-01 9.80686963e-01\n",
      " 9.88196909e-01 9.77183461e-01 9.82099771e-01 9.81307626e-01\n",
      " 9.82779205e-01 9.79711711e-01 1.40300845e-05 1.66902450e-04\n",
      " 4.59758849e-05 1.21722471e-04 1.46279868e-04 6.75163610e-05\n",
      " 7.12512629e-05 2.48558331e-06 8.67900671e-05 7.65300356e-05\n",
      " 3.32261698e-05 1.03927625e-04 9.45306529e-05 1.31636058e-04\n",
      " 1.29960419e-04 6.54019896e-05 4.27680643e-05 2.05464617e-04\n",
      " 8.71946395e-05 6.34655735e-05 4.12447152e-05 5.87357645e-05\n",
      " 6.60302248e-05 1.98026555e-05 8.77535203e-05 3.85611711e-05\n",
      " 8.69300038e-06 1.23321297e-04 4.94194865e-05 1.42066987e-04\n",
      " 1.24115133e-04 1.48849416e-04 2.65730760e-05 8.05298841e-05\n",
      " 1.24577316e-04 1.03850449e-04 1.32607121e-04 1.32315865e-04\n",
      " 2.81629491e-05 2.97145398e-05 6.00695857e-05 1.55769667e-04\n",
      " 3.72027389e-05 4.04749771e-05 1.12167341e-04 4.05740284e-05\n",
      " 3.43257940e-04 3.00988875e-04 4.03670856e-04 4.47906714e-05\n",
      " 5.89246454e-04 8.30284625e-05 1.03222432e-04 8.88484719e-05\n",
      " 1.06561085e-04 1.10448862e-04 1.20518471e-05 5.43207498e-05\n",
      " 3.77255637e-05 7.08434673e-05 1.04958912e-04 1.51796485e-04\n",
      " 1.80324987e-05 1.69818923e-05 1.63316858e-04 1.23260514e-04]\n",
      "target:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "before 64:\n",
      "0.0006439964\n",
      "64:\n",
      "0.97555506\n",
      "rounded\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# trying to view the model output\n",
    "out = model.predict(X_train_data)\n",
    "print(\"model prediction:\")\n",
    "print(out[0])\n",
    "print(\"target:\")\n",
    "print(Y_train_data[0])\n",
    "\n",
    "print(\"before 64:\")\n",
    "print(out[0][63])\n",
    "print(\"64:\")\n",
    "print(out[0][65])\n",
    "\n",
    "print(\"rounded\")\n",
    "print(np.round(out)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try visualizing this model at some point?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
