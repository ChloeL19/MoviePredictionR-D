{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloeloughridge/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This version uses a model architecture with two LSTM layers and a dropout layer in between\n",
    "# again, just using part1 data for training and validation\n",
    "\n",
    "# Here I will be building out the architecture of the first classification LSTM\n",
    "# At each time step, this LSTM will take in a vector representing the extracted audio and visual features from Liris-ACCEDE\n",
    "# Its goal is to output whether or not the movie induces fear at each time step\n",
    "\n",
    "\n",
    "# First, import necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting up the keras stuff\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import LSTM\n",
    "# my custom data_utils file\n",
    "from data_utils_local08 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 4096)\n"
     ]
    }
   ],
   "source": [
    "# uploading the X values\n",
    "X_input = load_Xinput(get_fc6_directory(7))\n",
    "print(X_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212,)\n"
     ]
    }
   ],
   "source": [
    "# uploading the Y values\n",
    "y_data_input = fear_oneHot(212, 'fear_annotations_part01/MEDIAEVAL18_7_Fear.txt')\n",
    "print(y_data_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 212, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Uploading part01 of the local fc6 data\n",
    "\n",
    "timesteps = 212   # the number of seconds in movie 07 --> i will figure out how to programmatically get this value\n",
    "data_dim = 4096    # the number of output values from VGG16 layer fc6 --> switch to programmatic later\n",
    "num_movies = 4\n",
    "batch_size = 7\n",
    "num_epochs = 5\n",
    "validation_num = 3\n",
    "\n",
    "# set up the X_train_data master array\n",
    "X_train_data = np.zeros([num_movies, timesteps, data_dim]) #oooooh this array will have to be as long as the longest\n",
    "                                                            # movie and padded with zeros --> this won't cause problems\n",
    "                                                            # right?\n",
    "X_valid_data = np.zeros([validation_num, timesteps, data_dim])\n",
    "        \n",
    "# for each movie number between and including 7 and 13\n",
    "for num in range(num_movies):\n",
    "    # load the X_input data\n",
    "    X_input = load_Xinput(get_fc6_directory(7 + num))\n",
    "    # put this X_input data into the X_train_data array\n",
    "    X_train_data[num, :, :] = X_input\n",
    "print(X_train_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 212, 4096)\n"
     ]
    }
   ],
   "source": [
    "# loading X validation set\n",
    "X_valid_data = np.zeros([validation_num, timesteps, data_dim])\n",
    "\n",
    "for num in range(validation_num):\n",
    "    # load the X_input data\n",
    "    X_valid = load_Xinput(get_fc6_directory(7 + num_movies + num))\n",
    "    # put this X_input data into the X_train_data array\n",
    "    X_valid_data[num, :, :] = X_valid\n",
    "print(X_valid_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# uploading the y data\n",
    "\n",
    "# set up y_train_data master array\n",
    "Y_train_data = np.zeros([num_movies, timesteps])\n",
    "\n",
    "# for each movie number between and including 7 and 13\n",
    "for num in range(num_movies):\n",
    "    # create the appropriate path to the fear annotation data\n",
    "    #print(num)\n",
    "    path = os.path.join('fear_annotations_part01/MEDIAEVAL18_{}_Fear.txt'.format(7+num))\n",
    "    # create a one-hot vector\n",
    "    y_data = fear_oneHot(timesteps, path)\n",
    "    # add this one-hot vector to y_train_data\n",
    "    Y_train_data[num, :] = y_data\n",
    "print(Y_train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# upload the Y validation set\n",
    "Y_valid_data = np.zeros([validation_num, timesteps])\n",
    "\n",
    "# for each movie number in validation set\n",
    "for num in range(validation_num):\n",
    "    # create the appropriate path to the fear annotation data\n",
    "    #print(num)\n",
    "    path = os.path.join('fear_annotations_part01/MEDIAEVAL18_{}_Fear.txt'.format(7+ num_movies + num))\n",
    "    # create a one-hot vector\n",
    "    y_valid = fear_oneHot(timesteps, path)\n",
    "    # add this one-hot vector to y_train_data\n",
    "    Y_valid_data[num, :] = y_valid\n",
    "print(Y_valid_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model architecture\n",
    "model = Sequential()\n",
    "model.add(LSTM(212, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))\n",
    "# dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# another LSTM layer\n",
    "model.add(LSTM(212, return_sequences=True))\n",
    "\n",
    "# necessary flatten layer\n",
    "model.add(Flatten()) \n",
    "\n",
    "# add the final dense layer and then softmax\n",
    "model.add(Dense(212, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a new metric of evaluation! the F-score!\n",
    "def FScore2(y_true, y_pred):\n",
    "    '''\n",
    "    The F score, beta=2\n",
    "    '''\n",
    "    B2 = K.variable(4)\n",
    "    OnePlusB2 = K.variable(5)\n",
    "    pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(K.less(K.abs(pred - K.clip(y_true, .5, 1.)), 0.01), 'float32'), -1)\n",
    "    fp = K.sum(K.cast(K.greater(pred - y_true, 0.1), 'float32'), -1)\n",
    "    fn = K.sum(K.cast(K.less(pred - y_true, -0.1), 'float32'), -1)\n",
    "\n",
    "    f2 = OnePlusB2 * tp / (OnePlusB2 * tp + B2 * fn + fp)\n",
    "\n",
    "    return K.mean(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compiling LSTM model\n",
    "# note that Ng used an Adam optimizer and categorical cross-entropy loss\n",
    "# but this is a binary classification problem so I think the parameters below should suffice\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy', FScore2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples, validate on 3 samples\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 4s 894ms/step - loss: 0.8194 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6816 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 3s 773ms/step - loss: 0.8150 - binary_accuracy: 0.8054 - FScore2: 0.0000e+00 - val_loss: 1.7320 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 4s 883ms/step - loss: 0.8055 - binary_accuracy: 0.8054 - FScore2: 0.0000e+00 - val_loss: 1.7915 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 3s 769ms/step - loss: 0.8017 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7218 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 3s 794ms/step - loss: 0.8024 - binary_accuracy: 0.8054 - FScore2: 0.0000e+00 - val_loss: 1.8761 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 3s 772ms/step - loss: 0.8010 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7814 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 3s 753ms/step - loss: 0.8003 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.9055 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 3s 738ms/step - loss: 0.8004 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.9103 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 3s 750ms/step - loss: 0.8041 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7219 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 3s 831ms/step - loss: 0.8030 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.8921 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 4s 942ms/step - loss: 0.8036 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.8087 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 4s 891ms/step - loss: 0.8078 - binary_accuracy: 0.8054 - FScore2: 0.0000e+00 - val_loss: 1.7573 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 4s 949ms/step - loss: 0.8054 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6622 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 3s 781ms/step - loss: 0.8093 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.8030 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 3s 756ms/step - loss: 0.8100 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6159 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 3s 829ms/step - loss: 0.8073 - binary_accuracy: 0.8054 - FScore2: 0.0000e+00 - val_loss: 1.7712 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 3s 874ms/step - loss: 0.8016 - binary_accuracy: 0.8054 - FScore2: 0.0000e+00 - val_loss: 1.7040 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 3s 784ms/step - loss: 0.8029 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7864 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 3s 761ms/step - loss: 0.8039 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6978 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 3s 734ms/step - loss: 0.8033 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.8155 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 3s 742ms/step - loss: 0.8008 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6937 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 4s 911ms/step - loss: 0.8032 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.8205 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 4s 991ms/step - loss: 0.8070 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6414 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 3s 715ms/step - loss: 0.8113 - binary_accuracy: 0.8054 - FScore2: 0.0000e+00 - val_loss: 1.7698 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 3s 740ms/step - loss: 0.8065 - binary_accuracy: 0.8054 - FScore2: 0.0000e+00 - val_loss: 1.6671 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 3s 753ms/step - loss: 0.8021 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7414 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 3s 719ms/step - loss: 0.8003 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7704 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 3s 739ms/step - loss: 0.8024 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7187 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 3s 738ms/step - loss: 0.8030 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6515 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 3s 731ms/step - loss: 0.8010 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7594 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 3s 770ms/step - loss: 0.7997 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7156 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 3s 742ms/step - loss: 0.8022 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7094 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 3s 754ms/step - loss: 0.8008 - binary_accuracy: 0.8054 - FScore2: 0.0000e+00 - val_loss: 1.7565 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 3s 719ms/step - loss: 0.7987 - binary_accuracy: 0.8054 - FScore2: 0.0000e+00 - val_loss: 1.7984 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 3s 775ms/step - loss: 0.7993 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7948 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 3s 871ms/step - loss: 0.8017 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.8457 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 4s 947ms/step - loss: 0.8033 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6704 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 3s 836ms/step - loss: 0.8064 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7342 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 3s 780ms/step - loss: 0.8067 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7624 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 3s 777ms/step - loss: 0.8058 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7571 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 3s 771ms/step - loss: 0.8036 - binary_accuracy: 0.8054 - FScore2: 0.0000e+00 - val_loss: 1.7361 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 3s 780ms/step - loss: 0.8031 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6729 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 3s 768ms/step - loss: 0.8003 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7757 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 3s 764ms/step - loss: 0.7990 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7399 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 3s 750ms/step - loss: 0.7988 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.8289 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 3s 755ms/step - loss: 0.8038 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6932 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 3s 745ms/step - loss: 0.8031 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7886 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.8004 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.8056 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 3s 750ms/step - loss: 0.7991 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6372 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 3s 754ms/step - loss: 0.8023 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.8839 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.7988 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7541 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 3s 740ms/step - loss: 0.7989 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7947 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 3s 756ms/step - loss: 0.7976 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.8264 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 3s 764ms/step - loss: 0.7966 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.8438 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 3s 768ms/step - loss: 0.7986 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7627 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 3s 764ms/step - loss: 0.8046 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7016 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 3s 755ms/step - loss: 0.8046 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7343 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 3s 740ms/step - loss: 0.7998 - binary_accuracy: 0.8054 - FScore2: 0.0000e+00 - val_loss: 1.6664 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 3s 761ms/step - loss: 0.7995 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.8127 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 3s 736ms/step - loss: 0.8032 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.5996 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 3s 759ms/step - loss: 0.8013 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.8026 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 3s 778ms/step - loss: 0.8005 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6335 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 3s 747ms/step - loss: 0.8008 - binary_accuracy: 0.8054 - FScore2: 0.0000e+00 - val_loss: 1.7739 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.7996 - binary_accuracy: 0.8054 - FScore2: 0.0000e+00 - val_loss: 1.6649 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 3s 747ms/step - loss: 0.8018 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.8294 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 3s 756ms/step - loss: 0.8021 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.5768 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 3s 755ms/step - loss: 0.7989 - binary_accuracy: 0.8054 - FScore2: 0.0000e+00 - val_loss: 1.7454 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 3s 744ms/step - loss: 0.7983 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7153 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 3s 799ms/step - loss: 0.7998 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7703 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7997 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7137 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 4s 909ms/step - loss: 0.7995 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7845 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.8002 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7330 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 4s 895ms/step - loss: 0.8011 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6722 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7990 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7369 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 4s 954ms/step - loss: 0.7969 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7109 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 3s 789ms/step - loss: 0.7960 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7623 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 4s 895ms/step - loss: 0.7961 - binary_accuracy: 0.8054 - FScore2: 0.0000e+00 - val_loss: 1.8291 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 3s 787ms/step - loss: 0.7980 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6857 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 3s 852ms/step - loss: 0.7999 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7774 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 3s 871ms/step - loss: 0.8018 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6383 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 3s 843ms/step - loss: 0.8003 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7463 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 3s 758ms/step - loss: 0.7988 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6288 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 3s 765ms/step - loss: 0.7974 - binary_accuracy: 0.8054 - FScore2: 0.0000e+00 - val_loss: 1.7001 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 3s 751ms/step - loss: 0.7974 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7718 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 3s 834ms/step - loss: 0.8031 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6738 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 3s 845ms/step - loss: 0.8016 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7628 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 3s 873ms/step - loss: 0.8005 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6017 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 4s 931ms/step - loss: 0.8002 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7585 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 3s 865ms/step - loss: 0.7964 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7053 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 3s 827ms/step - loss: 0.7963 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7796 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 3s 803ms/step - loss: 0.8017 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6975 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 3s 782ms/step - loss: 0.8045 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.5779 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 3s 866ms/step - loss: 0.7994 - binary_accuracy: 0.8054 - FScore2: 0.0000e+00 - val_loss: 1.6816 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 3s 806ms/step - loss: 0.7967 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6993 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 3s 776ms/step - loss: 0.7955 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7295 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 3s 757ms/step - loss: 0.7960 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7902 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7963 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.8352 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 3s 853ms/step - loss: 0.7992 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6751 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.8003 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.7067 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7985 - binary_accuracy: 0.8066 - FScore2: 0.1389 - val_loss: 1.6467 - val_binary_accuracy: 0.7689 - val_FScore2: 0.0000e+00\n",
      "finished training!\n"
     ]
    }
   ],
   "source": [
    "# running the LSTM model\n",
    "model.fit(X_train_data, Y_train_data, epochs = 100, validation_data=(X_valid_data, Y_valid_data))\n",
    "print(\"finished training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model prediction:\n",
      "[5.49479864e-07 5.93944719e-07 5.78420270e-07 5.83663393e-07\n",
      " 5.65004484e-07 5.71319617e-07 5.68758537e-07 5.76131754e-07\n",
      " 5.76161938e-07 5.51805670e-07 5.70887153e-07 5.70346799e-07\n",
      " 5.73387240e-07 5.64274842e-07 5.55580129e-07 5.73830334e-07\n",
      " 5.76743560e-07 5.86028818e-07 5.42460668e-07 5.77197000e-07\n",
      " 5.66496851e-07 5.77163974e-07 5.84629390e-07 5.46381159e-07\n",
      " 5.39094572e-07 5.61853597e-07 1.23930571e-04 1.49139509e-04\n",
      " 1.52143548e-04 1.13163369e-04 1.36380404e-04 1.29767621e-04\n",
      " 1.20852841e-04 1.01186968e-04 1.58411698e-04 1.22663376e-04\n",
      " 1.17308482e-04 3.56533419e-04 3.32202122e-04 1.16111369e-04\n",
      " 1.06199841e-04 1.19876968e-04 1.19230841e-04 1.61146963e-04\n",
      " 1.27709907e-04 8.63752794e-05 1.47213388e-04 1.22408324e-04\n",
      " 1.53755987e-04 1.18274947e-04 1.46849794e-04 1.04359366e-04\n",
      " 4.71320556e-04 3.61709448e-04 4.56058217e-04 4.02220903e-04\n",
      " 3.59833997e-04 4.11138346e-04 3.47381196e-04 3.03643988e-04\n",
      " 1.20189186e-04 1.42655670e-04 1.19914235e-04 1.07191670e-04\n",
      " 2.55331714e-02 2.93262284e-02 2.20157783e-02 3.29559557e-02\n",
      " 2.50488278e-02 3.15554813e-02 3.26276571e-02 2.99502164e-02\n",
      " 2.12567691e-02 2.03405824e-02 8.19871854e-03 7.89145194e-03\n",
      " 6.86142500e-03 7.67349219e-03 7.06467126e-03 8.39452446e-03\n",
      " 2.04537846e-02 1.95780918e-02 2.06747670e-02 2.34611277e-02\n",
      " 1.92401540e-02 6.84084091e-03 8.59888084e-03 6.32056780e-03\n",
      " 7.79525982e-03 8.17381777e-03 7.74321752e-03 7.39491777e-03\n",
      " 8.42303131e-03 8.39072280e-03 9.18000564e-03 2.37984732e-02\n",
      " 3.92058156e-02 4.34261113e-02 4.34955768e-02 2.30882838e-02\n",
      " 2.77155414e-02 2.26541236e-02 1.36979870e-04 1.37811847e-04\n",
      " 1.49771498e-04 2.33899802e-02 2.74761468e-02 2.72722133e-02\n",
      " 3.02677769e-02 2.36374680e-02 1.50749795e-04 1.35117851e-04\n",
      " 1.43701327e-04 1.27479201e-04 1.27969950e-04 1.30586122e-04\n",
      " 1.03993807e-04 1.14071590e-04 9.85068764e-05 1.20252596e-04\n",
      " 1.21299527e-04 1.12333983e-04 1.09925859e-04 1.22432844e-04\n",
      " 1.01556987e-04 1.14262562e-04 5.54822407e-07 5.71652606e-07\n",
      " 5.67245650e-07 8.04941449e-03 7.89306778e-03 7.68466992e-03\n",
      " 7.53176026e-03 6.33049291e-03 6.68582926e-03 7.56424433e-03\n",
      " 9.69121139e-03 9.36669111e-03 7.90661387e-03 7.92263821e-03\n",
      " 8.25504586e-03 7.20952637e-03 8.69943015e-03 6.65454054e-03\n",
      " 9.66137741e-03 8.07556137e-03 5.71644421e-07 5.89927652e-07\n",
      " 5.94977621e-07 5.95905476e-07 5.79258256e-07 5.72277202e-07\n",
      " 5.61141974e-07 5.62613934e-07 5.47186801e-07 5.90319871e-07\n",
      " 5.53156042e-07 5.80920698e-07 5.37800531e-07 5.82562336e-07\n",
      " 6.16167540e-07 6.06765752e-07 5.95811741e-07 5.61308923e-07\n",
      " 5.74167530e-07 5.78314371e-07 5.64368520e-07 5.50987977e-07\n",
      " 5.97517101e-07 5.66625488e-07 6.02635566e-07 5.72985471e-07\n",
      " 5.93484970e-07 5.69547240e-07 5.67061704e-07 5.89473245e-07\n",
      " 5.73098589e-07 5.77299943e-07 5.72125487e-07 5.49992592e-07\n",
      " 5.58405475e-07 5.68690268e-07 5.68349151e-07 5.98464908e-07\n",
      " 5.53769439e-07 5.96626592e-07 5.66497420e-07 5.86266367e-07\n",
      " 5.64780407e-07 5.64165646e-07 5.72015267e-07 5.94429196e-07\n",
      " 1.37829134e-04 1.05636056e-04 1.43849218e-04 1.51759232e-04\n",
      " 1.30498302e-04 5.66851384e-07 5.69192650e-07 5.97130850e-07\n",
      " 5.40017709e-07 5.69464135e-07 5.70142277e-07 5.85099031e-07\n",
      " 5.72176759e-07 5.55706720e-07 5.63471474e-07 5.29537431e-07\n",
      " 5.32427862e-07 5.39119242e-07 5.66797894e-07 5.76168532e-07]\n",
      "target:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "before 64:\n",
      "0.00010719167\n",
      "64:\n",
      "0.029326228\n",
      "rounded\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# trying to view the model output\n",
    "out = model.predict(X_train_data)\n",
    "print(\"model prediction:\")\n",
    "print(out[0])\n",
    "print(\"target:\")\n",
    "print(Y_train_data[0])\n",
    "\n",
    "print(\"before 64:\")\n",
    "print(out[0][63])\n",
    "print(\"64:\")\n",
    "print(out[0][65])\n",
    "\n",
    "print(\"rounded\")\n",
    "print(np.round(out)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try visualizing this model at some point?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
